## TiDB Cluster Part
[tidb_servers]
192.168.0.2

[tikv_servers]
192.168.0.3
192.168.0.4
192.168.0.5

[pd_servers]
192.168.0.6
192.168.0.7
192.168.0.8

[spark_master]

[spark_slaves]

## Monitoring Part
# prometheus and pushgateway servers
[monitoring_servers]
192.168.0.10

[grafana_servers]
192.168.0.10

# node_exporter and blackbox_exporter servers
[monitored_servers]
192.168.0.2
192.168.0.3
192.168.0.4
192.168.0.5
192.168.0.6
192.168.0.7
192.168.0.8
192.168.0.10

[alertmanager_servers]

[tidb_exporter_servers]

## Binlog Part
[pump_servers:children]
tidb_servers

## Group variables
[pd_servers:vars]
# location_labels = ["zone","rack","host"]

## Global variables
[all:vars]
deploy_dir = /home/tidb/deploy

## Connection
# ssh via normal user
ansible_user = tidb

# ssh via root:
# ansible_user = root
# ansible_become = true
# ansible_become_user = tidb

cluster_name = test-cluster

tidb_version = latest

# deployment methods, [binary, docker]
deployment_method = binary

# process supervision, [systemd, supervise]
process_supervision = systemd

# timezone of deployment region
timezone = Asia/Shanghai
set_timezone = True

enable_firewalld = False
# check NTP service
enable_ntpd = True
set_hostname = False

## binlog trigger
enable_binlog = False
# zookeeper address of kafka cluster, example:
# zookeeper_addrs = "192.168.0.11:2181,192.168.0.12:2181,192.168.0.13:2181"
zookeeper_addrs = ""

# store slow query log into seperate file
enable_slow_query_log = False

# enable TLS authentication in the TiDB cluster
enable_tls = False

# KV mode
deploy_without_tidb = False

# Optional. Set if you already have a alertmanager server.
# Format: alertmanager_host:alertmanager_port
alertmanager_target = ""
