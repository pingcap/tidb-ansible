#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

# Default system properties included when running spark-submit.
# This is useful for setting default environmental settings.

# Example:
# spark.eventLog.dir: "hdfs://namenode:8021/directory"
# spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dkey=value -Dnumbers="one two three"

spark.eventLog.enabled: false
spark.serializer: org.apache.spark.serializer.KryoSerializer
spark.driver.memory: 2g

# TiSpark configuration items 

# PD Cluster Addresses, split by comma.
# Do not need to fill, it will be automatically generated through ansible 
# spark.tispark.pd.addresses: 127.0.0.1:2379

# Max frame size of GRPC response 
spark.tispark.grpc.framesize: 268435456

# GRPC timeout time in seconds 
spark.tispark.grpc.timeout_in_sec: 100

# Metastore reload period in seconds 
spark.tispark.meta.reload_period_in_sec: 60

# If allow aggregation pushdown (in case of busy TiKV nodes) 
# spark.tispark.plan.allow_agg_pushdown: true

# If allow index double read (which might cause heavy pressure on TiKV) 
# spark.tispark.plan.allow_index_double_read: false

# How many row key in batch for concurrent index scan
# spark.tispark.index.scan_batch_size: 2000000

# Maximal threads for index scan retrieving row keys (shared among tasks inside each JVM) 
# spark.tispark.index.scan_concurrency: 2 

# Maximal threads for table scan (shared among tasks inside each JVM)
spark.tispark.table.scan_concurrency: 256 

# Can be "Low", "Normal", "High" ,which impacts resource to get in TiKV. Low is recommended for not disturbing OLTP workload 
spark.tispark.request.command.priority: "Low" 

# Whether to use streaming for response fetching 
# spark.tispark.coprocess.streaming: false

# A comma separated list of expressions. In case you have very old version of TiKV, you might disable some of the expression push-down if not supported 
# spark.tispark.plan.unsupported_pushdown_exprs: ""

# If index scan handles for one region exceeds this limit in original request, downgrade the request to a full table scan rather than original planned index scan 
# spark.tispark.plan.downgrade.index_threshold: 100000 

# An integer, represents timezone offset to UTC time(like 28800, GMT+8), this value will be added to requests issued to TiKV 
# spark.tispark.request.timezone.offset: 28800

#Whether to load statistics info automatically during database mapping
# spark.tispark.statistics.auto_load: true
# spark.tispark.plan.allow_index_read: true
