---
# Copyright 2016 PingCAP, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# See the License for the specific language governing permissions and
# limitations under the License.

# The playbook of TiDB

- name: check config locally
  hosts: localhost
  any_errors_fatal: true
  tags:
    - always
  roles:
    - check_config_static

- name: gather all facts, and check dest
  hosts: all
  any_errors_fatal: true
  tags:
    - always
  roles:
    - check_config_dynamic


- hosts: monitored_servers
  tags:
    - node_exporter
  tasks:
    - name: start node_exporter by supervise
      shell: cd {{ deploy_dir }}/scripts && ./start_node_exporter.sh
      when: process_supervision == 'supervise'

    - name: start node_exporter by systemd
      become: true
      systemd: name=node_exporter-{{ node_exporter_port }}.service state=started enabled=no
      when: process_supervision == 'systemd'

    - name: wait for node_exporter up
      wait_for: |
        host={{ ansible_host }} port={{ node_exporter_port }} state=present
        send='GET /metrics HTTP/1.0\r\n\r\n' search_regex='200 OK'


- hosts: monitored_servers
  tags:
    - blackbox_exporter
  tasks:
    - name: start blackbox_exporter by supervise
      shell: cd {{ deploy_dir }}/scripts && ./start_blackbox_exporter.sh
      when: process_supervision == 'supervise'

    - name: start blackbox_exporter by systemd
      become: true
      systemd: name=blackbox_exporter-{{ blackbox_exporter_port }}.service state=started enabled=no
      when: process_supervision == 'systemd'

    - name: wait for blackbox_exporter up
      wait_for: |
        host={{ ansible_host }} port={{ blackbox_exporter_port }} state=present
        send='GET / HTTP/1.0\r\n\r\n' search_regex='200 OK'


- hosts: alertmanager_servers
  tags:
    - alertmanager
  tasks:
    - name: start alertmanager by supervise
      shell: cd {{ deploy_dir }}/scripts && ./start_alertmanager.sh
      when: process_supervision == 'supervise'

    - name: start alertmanager by systemd
      systemd: name=alertmanager-{{ alertmanager_port }}.service state=started
      become: true
      when: process_supervision == 'systemd'

    - name: wait for alertmanager up
      wait_for: |
        host={{ ansible_host }} port={{ alertmanager_port }} state=present


- hosts: monitoring_servers
  tags:
    - pushgateway
    - prometheus
  tasks:
    - name: start monitoring modules by supervise
      shell: cd {{ deploy_dir }}/scripts && ./start_{{ item }}.sh
      when: process_supervision == 'supervise'
      with_items:
        - pushgateway
        - prometheus

    - name: start monitoring modules by systemd
      systemd: name={{ item }} state=started enabled=no
      when: process_supervision == 'systemd'
      become: true
      with_items:
        - pushgateway-{{ pushgateway_port }}.service
        - prometheus-{{ prometheus_port }}.service

    - name: wait for pushgateway up
      wait_for: |
        host={{ ansible_host }} port={{ pushgateway_port }} state=present
        send='GET /metrics HTTP/1.0\r\n\r\n' search_regex='200 OK'

    - name: wait for prometheus up
      wait_for: |
        host={{ ansible_host }} port={{ prometheus_port }} state=present
        send='GET /metrics HTTP/1.0\r\n\r\n' search_regex='200 OK'


- hosts: kafka_exporter_servers
  tags:
    - kafka_exporter
  tasks:
    - name: start kafka_exporter by supervise
      shell: cd {{ deploy_dir }}/scripts && ./start_kafka_exporter.sh
      when:
        - enable_binlog|default(false)
        - process_supervision == 'supervise'

    - name: start kafka_exporter by systemd
      become: true
      systemd: name=kafka_exporter-{{ kafka_exporter_port }}.service state=started enabled=no
      when:
        - enable_binlog|default(false)
        - process_supervision == 'systemd'

    - name: wait for kafka_exporter up
      wait_for: |
        host={{ ansible_host }} port={{ kafka_exporter_port }} state=present
      when: enable_binlog|default(false)


- hosts: pd_servers
  tags:
    - pd
  tasks:
    - name: start PD by supervise
      shell: cd {{ deploy_dir }}/scripts && ./start_{{ item }}.sh
      when: process_supervision == 'supervise'
      with_items:
        - pd

    - name: start PD by systemd
      systemd: name=pd.service state=started enabled=no
      become: true
      when: process_supervision == 'systemd'

    - name: wait for PD up
      wait_for: |
        host={{ ansible_host }} port={{ pd_client_port }} state=present
        send='GET /pd/api/v1/members HTTP/1.0\r\n\r\n' search_regex='200 OK'
      when: not enable_tls|default(false)

    - name: wait for PD up
      uri:
        url: "https://{{ ansible_host }}:{{ pd_client_port }}/pd/api/v1/members"
        validate_certs: no
        client_cert: "{{ pd_cert_dir }}/pd-server-{{ ansible_host }}.pem"
        client_key: "{{ pd_cert_dir }}/pd-server-{{ ansible_host }}-key.pem"
      register: result
      until: result.status is defined and result.status == 200
      retries: 10
      delay: 5
      when: enable_tls|default(false) 


- hosts: tikv_servers
  tags:
    - tikv
  tasks:
    - name: start TiKV by supervise
      shell: cd {{ deploy_dir }}/scripts && ./start_{{ item }}.sh
      when: process_supervision == 'supervise'
      with_items:
        - tikv

    - name: start TiKV by systemd
      systemd: name=tikv-{{ tikv_port }}.service state=started enabled=no
      become: true
      when: process_supervision == 'systemd'

    - name: wait for TiKV up
      wait_for_pid: |
        pid_file={{ deploy_dir }}/status/tikv.pid timeout=300
        thread_name_regex='tikv-server' state=present
      when: deployment_method == 'binary'

    - name: wait for TiKV up
      wait_for: host={{ ansible_host }} port={{ tikv_port }} state=present
      when: deployment_method == 'docker'

    - command: cat {{ deploy_dir }}/status/tikv.pid
      register: new_tikv_pid
      ignore_errors: yes
      changed_when: false

    - name: display new tikv pid
      debug:
        msg: "tikv binary or docker pid: {{ new_tikv_pid.stdout }}"


- hosts: tidb_servers
  tags:
    - tidb
  tasks:
    - name: clean pump .node file
      file: path={{ pump_data_dir }}/.node state=absent
      when: enable_binlog|default(false)

    - name: start pump by supervise
      shell: cd {{ deploy_dir }}/scripts && ./start_{{ item }}.sh
      when:
        - enable_binlog|default(false)
        - process_supervision == 'supervise'
      with_items:
        - pump

    - name: start pump by systemd
      systemd: name=pump.service state=started enabled=no
      become: true
      when:
        - enable_binlog|default(false)
        - process_supervision == 'systemd'

    - name: wait for pump up
      wait_for: |
        host={{ ansible_host }} port={{ pump_port }} state=present
      when: enable_binlog|default(false)

    - name: start TiDB by supervise
      shell: cd {{ deploy_dir }}/scripts && ./start_{{ item }}.sh
      when: process_supervision == 'supervise'
      with_items:
        - tidb

    - name: start TiDB by systemd
      systemd: name=tidb-{{ tidb_port }}.service state=started enabled=no
      become: true
      when: process_supervision == 'systemd'

    - name: wait for TiDB up
      wait_for: |
        host={{ ansible_host }} port={{ tidb_status_port }} state=present
        send='GET /status HTTP/1.0\r\n\r\n' search_regex='TiDB'
      when: not enable_tls|default(false)

    - name: wait for TiDB up
      uri:
        url: "https://{{ ansible_host }}:{{ tidb_status_port }}/status"
        validate_certs: no
        client_cert: "{{ tidb_cert_dir }}/tidb-server-{{ ansible_host }}.pem"
        client_key: "{{ tidb_cert_dir }}/tidb-server-{{ ansible_host }}-key.pem"
      register: result
      until: result.status is defined and result.status == 200
      retries: 10
      delay: 5
      when: enable_tls|default(false)


- hosts: grafana_servers
  tags:
    - grafana
  roles:
    - { role: grafana, grafana_exec_vars_only: true }
  tasks:
    - name: start grafana by supervise
      shell: cd {{ deploy_dir }}/scripts && ./start_{{ item }}.sh
      when: process_supervision == 'supervise'
      with_items:
        - grafana

    - name: start grafana by systemd
      systemd: name=grafana-{{ grafana_port }}.service state=started enabled=no
      when: process_supervision == 'systemd'
      become: true

    - name: wait for grafana up
      wait_for: |
        host={{ ansible_host }} port={{ grafana_port }} state=present
        send='GET /login HTTP/1.0\r\n\r\n' search_regex='200 OK'

    - name: start grafana_collector by supervise
      shell: cd {{ deploy_dir }}/scripts && ./start_{{ item }}.sh
      when: process_supervision == 'supervise'
      with_items:
        - grafana_collector

    - name: start grafana_collector by systemd
      systemd: name=grafana_collector-{{ grafana_collector_port }}.service state=started enabled=no
      when: process_supervision == 'systemd'
      become: true

    - name: wait for grafana_collector up
      wait_for: |
        host={{ ansible_host }} port={{ grafana_collector_port }} state=present

    - set_fact:
        grafana_host: "{{ ansible_host }}"

    - include_tasks: create_grafana_api_keys.yml

    - name: import grafana data source
      shell: >
        chdir={{ grafana_data_dir }}
        warn=no
        curl -q -X POST -d @data_source.json --header 'Content-Type: application/json'
        "http://{{ grafana_admin_user }}:{{ grafana_admin_password }}@127.0.0.1:{{ grafana_port }}/api/datasources"

    - name: import grafana dashboards - prepare config
      delegate_to: localhost
      template: src=grafana.dest.json.j2 dest={{ playbook_dir }}/scripts/dests.json
      vars:
        - ansible_become: false
        - ansible_connection: local
        - grafana_dest_config:
            name: "{{ cluster_name | title }}"
            url: "http://{{ grafana_host }}:{{ grafana_port }}/"
            report_url: "http://{{ grafana_host }}:{{ grafana_collector_port }}/"
            user: "{{ grafana_admin_user }}"
            password: "{{ grafana_admin_password }}"
            apikey: "{{ lookup('file', grafana_api_keys_dir + '/grafana_apikey.key') }}"
            datasource: "{{ cluster_name }}"
            titles:
              node: "{{ cluster_name | title }}-Node_exporter"
              pd:   "{{ cluster_name | title }}-PD"
              tidb: "{{ cluster_name | title }}-TiDB"
              tikv: "{{ cluster_name | title }}-TiKV"
              tikv_instances: "{{ cluster_name | title }}-TiKV-Instances"
              binlog: "{{ cluster_name | title }}-Binlog"
              overview: "{{ cluster_name | title }}-Overview"
              disk_performance: "{{ cluster_name | title }}-Disk-Performance"
              blackbox_exporter: "{{ cluster_name | title }}-Blackbox_exporter"
              kafka_overview: "{{ cluster_name | title }}-Kafka-Overview"

    - name: import grafana dashboards - run import script
      delegate_to: localhost
      shell: >-
        chdir={{ playbook_dir }}/scripts
        ./grafana-config-copy.py
      vars:
        - ansible_become: false
        - ansible_connection: local
