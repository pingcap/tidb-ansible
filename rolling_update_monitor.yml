---
# Copyright 2016 PingCAP, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# See the License for the specific language governing permissions and
# limitations under the License.

# The rolling update playbook of TiDB

- name: check config locally
  hosts: localhost
  any_errors_fatal: true
  tags:
    - always
  roles:
    - check_config_static

- name: gather all facts, and check dest
  hosts: all
  any_errors_fatal: true
  tags:
    - always
  roles:
    - check_config_dynamic


- name: rolling update node_exporter
  hosts: monitored_servers
  any_errors_fatal: true
  tags:
    - node_exporter

  pre_tasks:
    - name: check node_exporter existed
      stat:
        path: "{{ deploy_dir }}/bin/node_exporter"
      register: node_exporter_binary_file

    - name: stop node_exporter by supervise
      shell: cd {{ deploy_dir }}/scripts && ./stop_node_exporter.sh
      when:
        - process_supervision == 'supervise'
        - node_exporter_binary_file.stat.exists == True

    - name: stop node_exporter by systemd
      systemd: name=node_exporter-{{ node_exporter_port }}.service state=stopped
      become: true
      when:
        - process_supervision == 'systemd'
        - node_exporter_binary_file.stat.exists == True

    - name: wait until the node_exporter port is down
      wait_for:
        host: "{{ ansible_host }}"
        port: "{{ node_exporter_port }}"
        state: stopped
        msg: "the node_exporter port {{ node_exporter_port }} is not down"

  roles:
    - node_exporter

  post_tasks:
    - name: start node_exporter by supervise
      shell: cd {{ deploy_dir }}/scripts && ./start_node_exporter.sh
      when: process_supervision == 'supervise'

    - name: start node_exporter by systemd
      systemd: name=node_exporter-{{ node_exporter_port }}.service state=started
      become: true
      when: process_supervision == 'systemd'

    - name: wait until the node_exporter port is up
      wait_for:
        host: "{{ ansible_host }}"
        port: "{{ node_exporter_port }}"
        state: started
        msg: "the node_exporter port {{ node_exporter_port }} is not up"

    - name: wait until the node_exporter metrics page is available
      uri:
        url: "http://{{ ansible_host }}:{{ node_exporter_port }}/metrics"
      register: node_exporter_http_result
      until: node_exporter_http_result.status == 200
      retries: 12
      delay: 5


- name: rolling update blackbox_exporter
  hosts: monitored_servers
  any_errors_fatal: true
  tags:
    - blackbox_exporter

  pre_tasks:
    - name: check blackbox_exporter existed
      stat:
        path: "{{ deploy_dir }}/conf/blackbox.yml"
      register:  blackbox_exporter_configure_file

    - name: stop blackbox_exporter by supervise
      shell: cd {{ deploy_dir }}/scripts && ./stop_blackbox_exporter.sh
      when:
        - process_supervision == 'supervise'
        - blackbox_exporter_configure_file.stat.exists == True

    - name: stop blackbox_exporter by systemd
      systemd: name=blackbox_exporter-{{ blackbox_exporter_port }}.service state=stopped
      become: true
      when:
        - process_supervision == 'systemd'
        - blackbox_exporter_configure_file.stat.exists == True

    - name: wait until the blackbox_exporter port is down
      wait_for:
        host: "{{ ansible_host }}"
        port: "{{ blackbox_exporter_port }}"
        state: stopped
        msg: "the blackbox_exporter port {{ blackbox_exporter_port }} is not down"

  roles:
    - blackbox_exporter

  post_tasks:
    - name: start blackbox_exporter by supervise
      shell: cd {{ deploy_dir }}/scripts && ./start_blackbox_exporter.sh
      when: process_supervision == 'supervise'

    - name: start blackbox_exporter by systemd
      systemd: name=blackbox_exporter-{{ blackbox_exporter_port }}.service state=started
      become: true
      when: process_supervision == 'systemd'

    - name: wait until the blackbox_exporter port is up
      wait_for:
        host: "{{ ansible_host }}"
        port: "{{ blackbox_exporter_port }}"
        state: started
        msg: "the blackbox_exporter port {{ blackbox_exporter_port }} is not up"

    - name: wait until the blackbox_exporter metrics page is available
      uri:
        url: "http://{{ ansible_host }}:{{ blackbox_exporter_port }}/metrics"
      register: blackbox_exporter_http_result
      until: blackbox_exporter_http_result.status == 200
      retries: 12
      delay: 5


- name: rolling update alertmanager
  hosts: alertmanager_servers
  any_errors_fatal: true
  tags:
    - alertmanager

  pre_tasks:
    - name: check alertmanager existed
      stat:
        path: "{{ deploy_dir }}/conf/alertmanager.yml"
      register:  alertmanager_configure_file

    - name: stop alertmanager by supervise
      shell: cd {{ deploy_dir }}/scripts && ./stop_alertmanager.sh
      when:
        - process_supervision == 'supervise'
        - alertmanager_configure_file.stat.exists == True

    - name: stop alertmanager by systemd
      systemd: name=alertmanager-{{ alertmanager_port }}.service state=stopped
      become: true
      when:
        - process_supervision == 'systemd'
        - alertmanager_configure_file.stat.exists == True

    - name: wait until the alertmanager port is down
      wait_for:
        host: "{{ ansible_host }}"
        port: "{{ alertmanager_port }}"
        state: stopped
        msg: "the alertmanager port {{ alertmanager_port }} is not down"

  roles:
    - alertmanager

  post_tasks:
    - name: start alertmanager by supervise
      shell: cd {{ deploy_dir }}/scripts && ./start_alertmanager.sh
      when: process_supervision == 'supervise'

    - name: start alertmanager by systemd
      systemd: name=alertmanager-{{ alertmanager_port }}.service state=started
      become: true
      when: process_supervision == 'systemd'

    - name: wait until the alertmanager port is up
      wait_for:
        host: "{{ ansible_host }}"
        port: "{{ alertmanager_port }}"
        state: started
        msg: "the alertmanager port {{ alertmanager_port }} is not up"


- name: rolling update pushgateway
  hosts: monitoring_servers
  any_errors_fatal: true
  tags:
    - pushgateway

  pre_tasks:
    - name: stop pushgateway by supervise
      shell: cd {{ deploy_dir }}/scripts && ./stop_{{ item }}.sh
      with_items:
        - pushgateway
      when: process_supervision == 'supervise'

    - name: stop pushgateway by systemd
      systemd: name={{ item }} state=stopped
      when: process_supervision == 'systemd'
      become: true
      with_items:
        - pushgateway-{{ pushgateway_port }}.service

    - name: wait until the pushgateway port is down
      wait_for:
        host: "{{ ansible_host }}"
        port: "{{ pushgateway_port }}"
        state: stopped
        msg: "the pushgateway port {{ pushgateway_port }} is not down"

  roles:
    - pushgateway

  post_tasks:
    - name: start pushgateway by supervise
      shell: cd {{ deploy_dir }}/scripts && ./start_{{ item }}.sh
      when: process_supervision == 'supervise'
      with_items:
        - pushgateway

    - name: start pushgateway by systemd
      systemd: name={{ item }} state=started enabled=no
      when: process_supervision == 'systemd'
      become: true
      with_items:
        - pushgateway-{{ pushgateway_port }}.service

    - name: wait until the pushgateway port is up
      wait_for:
        host: "{{ ansible_host }}"
        port: "{{ pushgateway_port }}"
        state: started
        msg: "the pushgateway port {{ pushgateway_port }} is not up"

    - name: wait until the pushgateway metrics page is available
      uri:
        url: "http://{{ ansible_host }}:{{ pushgateway_port }}/metrics"
      register: pushgateway_http_result
      until: pushgateway_http_result.status == 200
      retries: 12
      delay: 5


- name: rolling update prometheus
  hosts: monitoring_servers
  any_errors_fatal: true
  tags:
    - prometheus

  pre_tasks:
    - name: stop prometheus by supervise
      shell: cd {{ deploy_dir }}/scripts && ./stop_{{ item }}.sh
      with_items:
        - prometheus
      when: process_supervision == 'supervise'

    - name: stop prometheus by systemd
      systemd: name={{ item }} state=stopped
      when: process_supervision == 'systemd'
      become: true
      with_items:
        - prometheus-{{ prometheus_port }}.service

    - name: wait until the prometheus port is down
      wait_for:
        host: "{{ ansible_host }}"
        port: "{{ prometheus_port }}"
        state: stopped
        msg: "the prometheus port {{ prometheus_port }} is not down"

  roles:
    - prometheus

  post_tasks:
    - name: start prometheus by supervise
      shell: cd {{ deploy_dir }}/scripts && ./start_{{ item }}.sh
      when: process_supervision == 'supervise'
      with_items:
        - prometheus

    - name: start prometheus by systemd
      systemd: name={{ item }} state=started enabled=no
      when: process_supervision == 'systemd'
      become: true
      with_items:
        - prometheus-{{ prometheus_port }}.service

    - name: wait until the prometheus port is up
      wait_for:
        host: "{{ ansible_host }}"
        port: "{{ prometheus_port }}"
        state: started
        msg: "the prometheus port {{ prometheus_port }} is not up"

    - name: wait until the prometheus metrics page is available
      uri:
        url: "http://{{ ansible_host }}:{{ prometheus_port }}/metrics"
      register: prometheus_http_result
      until: prometheus_http_result.status == 200
      retries: 12
      delay: 5


- name: rolling update grafana
  hosts: grafana_servers
  any_errors_fatal: true
  tags:
    - grafana

  pre_tasks:
    - name: stop grafana by supervise
      shell: cd {{ deploy_dir }}/scripts && ./stop_{{ item }}.sh
      when: process_supervision == 'supervise'
      with_items:
        - grafana

    - name: stop grafana by systemd
      systemd: name=grafana-{{ grafana_port }}.service state=stopped
      become: true
      when: process_supervision == 'systemd'

    - name: wait until the grafana port is down
      wait_for:
        host: "{{ ansible_host }}"
        port: "{{ grafana_port }}"
        state: stopped
        msg: "the grafana port {{ grafana_port }} is not down"

  roles:
    - grafana

  post_tasks:
    - name: start grafana by supervise
      shell: cd {{ deploy_dir }}/scripts && ./start_{{ item }}.sh
      when: process_supervision == 'supervise'
      with_items:
        - grafana

    - name: start grafana by systemd
      systemd: name=grafana-{{ grafana_port }}.service state=started enabled=no
      when: process_supervision == 'systemd'
      become: true

    - name: wait until the grafana port is up
      wait_for:
        host: "{{ ansible_host }}"
        port: "{{ grafana_port }}"
        state: started
        msg: "the grafana port {{ grafana_port }} is not up"

    - name: wait until the grafana login page is available
      uri:
        url: "http://{{ ansible_host }}:{{ grafana_port }}/login"
      register: grafana_http_result
      until: grafana_http_result.status == 200
      retries: 12
      delay: 5

    - set_fact:
        grafana_host: "{{ ansible_host }}"

    - include_tasks: "common_tasks/create_grafana_api_keys.yml"

    - name: import grafana data source
      shell: >
        chdir={{ grafana_data_dir }}
        warn=no
        curl -q -X POST -d @data_source.json --header 'Content-Type: application/json'
        "http://{{ grafana_admin_user }}:{{ grafana_admin_password }}@127.0.0.1:{{ grafana_port }}/api/datasources"

    - name: import grafana dashboards - prepare config
      delegate_to: localhost
      template: src=grafana.dest.json.j2 dest={{ playbook_dir }}/scripts/dests.json
      vars:
        - ansible_become: false
        - ansible_connection: local
        - grafana_dest_config:
            name: "{{ cluster_name | title }}"
            url: "http://{{ grafana_host }}:{{ grafana_port }}/"
            user: "{{ grafana_admin_user }}"
            password: "{{ grafana_admin_password }}"
            apikey: "{{ lookup('file', grafana_api_keys_dir + '/grafana_apikey.key') }}"
            datasource: "{{ cluster_name }}"
            titles:
              node: "{{ cluster_name | title }}-Node_exporter"
              pd:   "{{ cluster_name | title }}-PD"
              tidb: "{{ cluster_name | title }}-TiDB"
              tidb_summary: "{{ cluster_name | title }}-TiDB-Summary"
              tikv_summary: "{{ cluster_name | title }}-TiKV-Summary"
              tikv_details: "{{ cluster_name | title }}-TiKV-Details"
              tikv_trouble_shot: "{{ cluster_name | title }}-TiKV-Trouble-Shooting"
              binlog: "{{ cluster_name | title }}-Binlog"
              overview: "{{ cluster_name | title }}-Overview"
              disk_performance: "{{ cluster_name | title }}-Disk-Performance"
              blackbox_exporter: "{{ cluster_name | title }}-Blackbox_exporter"
              kafka_overview: "{{ cluster_name | title }}-Kafka-Overview"
              lightning: "{{ cluster_name | title }}-Lightning"
              performance_read: "{{ cluster_name | title }}-Performance-Read"
              performance_write: "{{ cluster_name | title }}-Performance-Write"

    - name: import grafana dashboards - run import script
      delegate_to: localhost
      shell: "python grafana-config-copy.py"
      args:
        chdir: "{{ playbook_dir }}/scripts"
      vars:
        - ansible_become: false
        - ansible_connection: local


- name: rolling update kafka_exporter
  hosts: kafka_exporter_servers
  any_errors_fatal: true
  tags:
    - kafka_exporter

  pre_tasks:
    - name: check kafka_exporter existed
      stat:
        path: "{{ deploy_dir }}/bin/kafka_exporter"
      register:  kafka_exporter_binary_file
      when: enable_binlog|default(false)

    - name: stop kafka_exporter by supervise
      shell: cd {{ deploy_dir }}/scripts && ./stop_kafka_exporter.sh
      when:
        - enable_binlog|default(false)
        - process_supervision == 'supervise'
        - kafka_exporter_binary_file.stat.exists == True

    - name: stop kafka_exporter by systemd
      become: true
      systemd: name=kafka_exporter-{{ kafka_exporter_port }}.service state=stopped enabled=no
      when:
        - enable_binlog|default(false)
        - process_supervision == 'systemd'
        - kafka_exporter_binary_file.stat.exists == True

    - name: wait until the kafka_exporter port is down
      wait_for:
        host: "{{ ansible_host }}"
        port: "{{ kafka_exporter_port }}"
        state: stopped
        msg: "the kafka_exporter port {{ kafka_exporter_port }} is not down"
      when: enable_binlog|default(false)

  roles:
    - { role: kafka_exporter, when: 'enable_binlog|default(false) and kafka_addrs|default("") != ""' }

  post_tasks:
    - name: start kafka_exporter by supervise
      shell: cd {{ deploy_dir }}/scripts && ./start_kafka_exporter.sh
      when:
        - enable_binlog|default(false)
        - process_supervision == 'supervise'

    - name: start kafka_exporter by systemd
      become: true
      systemd: name=kafka_exporter-{{ kafka_exporter_port }}.service state=started enabled=no
      when:
        - enable_binlog|default(false)
        - process_supervision == 'systemd'

    - name: wait until the kafka_exporter port is up
      wait_for:
        host: "{{ ansible_host }}"
        port: "{{ kafka_exporter_port }}"
        state: started
        msg: "the kafka_exporter port {{ kafka_exporter_port }} is not up"
      when: enable_binlog|default(false)
