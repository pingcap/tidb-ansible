---

- name: deploy spark-2.4.3-bin-hadoop2.7
  unarchive: >
    creates="{{ deploy_dir }}/spark/sbin/start-master.sh"
    src={{ downloads_dir }}/spark-2.4.3-bin-hadoop2.7.tgz dest={{ deploy_dir }}/

- name: rename spark deploy dir
  shell: >
    creates="{{ deploy_dir }}/spark/sbin/start-master.sh"
    mv {{ deploy_dir }}/spark-* "{{ deploy_dir }}/spark"

- name: deploy tispark
  copy:
    src: "{{ resources_dir }}/bin/tispark-assembly-SNAPSHOT.jar"
    dest: "{{ deploy_dir }}/spark/jars/"

- name: load customized spark_env
  include_vars: file={{ playbook_dir }}/conf/spark-env.yml name=spark_env_custom

- name: create spark_env.sh file
  template:
    src: spark-env.sh.j2
    dest: "{{ deploy_dir }}/spark/conf/spark-env.sh"
    mode: 0644
    backup: yes

- name: load customized spark_defaults
  include_vars: file={{ playbook_dir }}/conf/spark-defaults.yml name=spark_defaults_custom

- name: create spark_defaults.conf file
  template:
    src: spark-defaults.conf.j2
    dest: "{{ deploy_dir }}/spark/conf/spark-defaults.conf"
    mode: 0644
    backup: yes

- name: create spark-slave.sh
  template:
    src: "start-slave.sh.j2"
    dest: "{{ deploy_dir }}/spark/sbin/start-slave.sh"
    mode: 0755
    backup: yes
  when: "'spark_slaves' in group_names"

- name: create log4j.properties file
  template:
    src: log4j.properties.j2
    dest: "{{ deploy_dir }}/spark/conf/log4j.properties"
    mode: 0644
    backup: yes
