{% set my_ip = ansible_default_ipv4.address -%}
{# my id in tikv cluster #}
{% set my_peer_id = groups.tikv_servers.index(inventory_hostname) + 1 -%}
{% set all_pd = [] -%}
{% set pd_hosts = groups.pd_servers %}
{% for host in pd_hosts -%}
  {% set pd_ip = hostvars[host].ansible_default_ipv4.address -%}
  {% set pd_port = hostvars[host].pd_client_port -%}
  {% set _ = all_pd.append("%s:%s" % (pd_ip, pd_port)) -%}
{% endfor -%}

{% set metric_host = hostvars[groups.monitoring_servers[0]].ansible_default_ipv4.address
    if groups.get('monitoring_servers', []) else '' -%}
{% set metric_port = hostvars[groups.monitoring_servers[0]].pushgateway_port if metric_host else ''-%}
{% set metric_interval = tikv_metric_interval if metric_host else "0s" -%}

# TiKV config template
#  Human-readable big numbers:
#   File size(based on byte): KB, MB, GB, TB, PB (or lowercase)
#    e.g.: 1_048_576 = "1MB"
#   Time(based on ms): ms, s, m, h
#    e.g.: 78_000 = "1.3m"

[server]
# listening address.
addr = "0.0.0.0:{{ tikv_port }}"
# leave empty, fallback to use addr
advertise-addr = "{{ my_ip }}:{{ tikv_port }}"

# set which dsn to use, warning: default is rocksdb without persistent.
dsn = "rocksdb"
# set the path to rocksdb directory.
store = "{{ tikv_data_dir }}"

# log level: trace, debug, info, warn, error, off.
log-level = "{{ tikv_log_level }}"

log-file = "{{ tikv_log_dir }}/{{ tikv_log_filename }}"

# notify capacity, 40960 is suitable for about 7000 regions.
notify-capacity = 40960
# maximum number of messages can be processed in one tick.
messages-per-tick = 4096
# socket send/recv buffer size.
send-buffer-size = "128KB"
recv-buffer-size = "128KB"
# size of thread pool for endpoint task
end-point-concurrency = 8

# set store capacity, if no set, use unlimited or disk size later.
# 0 is unlimited.
# capacity = "{{ tikv_capacity }}"

[pd]
# pd endpoints
endpoints = "{{ all_pd | join(',') }}"

[metric]
# the Prometheus client push interval.
# Setting the value to 0s stops Prometheus client from pushing.
interval = "{{ metric_interval }}"

# the Prometheus pushgateway address. Leaving it empty stops Prometheus client from pushing.
address = "{{ metric_host ~ ":" ~ metric_port if metric_host else "" }}"

# the Prometheus client push job name. Note: A node id will automatically append,
# e.g., "tikv_1".
job = "{{ tikv_metric_job_name_prefix }}"


################################################################################
################################### Config for CNCF
################################################################################

[raftstore]
notify-capacity = 40960
messages-per-tick = 4096
pd-heartbeat-tick-interval = "60s"
pd-store-heartbeat-tick-interval = "10s"
region-max-size = "80MB"
region-split-size = "64MB"
region-split-check-diff = "8MB"
split-region-check-tick-interval = "5s"
max-peer-down-duration = "5m"

[rocksdb]
max-background-compactions = 8
max-background-flushes = 8
max-open-files = 8192
max-manifest-file-size = "20MB"
create-if-missing = true
wal-recovery-mode = 2
enable-statistics = false
stats-dump-period-sec = 600

[rocksdb.defaultcf]
compression-per-level = "no:no:lz4:lz4:lz4:lz4:lz4"
block-size = "64KB"
bloom-filter-bits-per-key = 10
block-based-bloom-filter = false
level0-slowdown-writes-trigger = 12
level0-stop-writes-trigger = 16
write-buffer-size = "128MB"
max-write-buffer-number = 5
min-write-buffer-number-to-merge = 1
max-bytes-for-level-base = "512MB"
target-file-size-base = "32MB"
block-cache-size = "3GB"

[rocksdb.writecf]
compression-per-level = "no:no:lz4:lz4:lz4:lz4:lz4"
block-size = "64KB"
write-buffer-size = "128MB"
max-write-buffer-number = 5
min-write-buffer-number-to-merge = 1
max-bytes-for-level-base = "512MB"
target-file-size-base = "32MB"
block-cache-size = "1GB"

[rocksdb.raftcf]
compression-per-level = "no:no:lz4:lz4:lz4:lz4:lz4"
block-size = "64KB"
write-buffer-size = "64MB"
max-write-buffer-number = 5
min-write-buffer-number-to-merge = 1
max-bytes-for-level-base = "256MB"
target-file-size-base = "32MB"
block-cache-size = "512MB"


[storage]
scheduler-notify-capacity = 10240
scheduler-messages-per-tick = 1024
scheduler-concurrency = 102400
scheduler-worker-pool-size = 8
